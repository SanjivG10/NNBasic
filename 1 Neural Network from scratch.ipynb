{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self,inputs,outputs,outputActivation=\"softmax\",epochs=100,learning_rate=0.001,validation=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.layers = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.actual_outputs= []\n",
    "        self.activations = []\n",
    "        self.deltas = []\n",
    "        self.delta_weights = []\n",
    "        self.delta_biases = []\n",
    "        self.outputActivation=outputActivation, \n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.validation=validation\n",
    "    def add_layer(self,layer_num,activation='sigmoid'):\n",
    "        self.layers.append({\n",
    "            \"index\" : len(self.layers),\n",
    "            \"layer_num\":layer_num,\n",
    "            \"activation\": activation\n",
    "        })\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        if hasattr(self.inputs[0], \"__len__\"):\n",
    "            inputWeight = len(self.inputs[0])\n",
    "        else:\n",
    "            inputWeight = 1\n",
    "            \n",
    "        if hasattr(self.outputs[0], \"__len__\"):\n",
    "            outputWeight = len(self.outputs[0])\n",
    "        else:\n",
    "            outputWeight = 1\n",
    "        for index,eachLayer in enumerate(self.layers):\n",
    "            if index==0:\n",
    "                self.weights.append(np.random.rand(eachLayer[\"layer_num\"],inputWeight))\n",
    "                self.biases.append(np.random.rand(eachLayer[\"layer_num\"],1))                \n",
    "            else:\n",
    "                self.weights.append(np.random.rand(self.layers[index][\"layer_num\"],self.layers[index-1][\"layer_num\"]))\n",
    "                self.biases.append(np.random.rand(eachLayer[\"layer_num\"],1))\n",
    "                \n",
    "                if index==len(self.layers)-1:\n",
    "                    self.weights.append(np.random.rand(outputWeight,self.layers[index][\"layer_num\"]))\n",
    "                    self.biases.append(np.random.rand(outputWeight,1))\n",
    "                    \n",
    "    def sigmoid(self,x,derivative=False):\n",
    "        if derivative:\n",
    "            return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "        else:\n",
    "            return 1/(1+np.exp(-x))\n",
    "                \n",
    "    def softmax(self,X):\n",
    "        eachV = []\n",
    "        for eachX in X:\n",
    "            eachV.append(np.exp(eachX)/np.sum(np.exp(X)))\n",
    "        return np.array(eachV)\n",
    "                                    \n",
    "    def feed_forward(self):\n",
    "        \n",
    "        for eachIndex in range(len(self.inputs)):\n",
    "            activations = []\n",
    "            actual_outputs = []\n",
    "            for index,eachLayer in enumerate(self.layers):\n",
    "                if index==0:\n",
    "                    if eachLayer[\"activation\"]==\"sigmoid\":\n",
    "                        actual_outputs.append(np.dot(self.weights[index],self.inputs[eachIndex]) + self.biases[index])\n",
    "                        activations.append(self.sigmoid(actual_outputs[-1]))\n",
    "                else:\n",
    "                    if eachLayer[\"activation\"]==\"sigmoid\":\n",
    "                        actual_outputs.append(np.dot(self.weights[index],activations[-1]) + self.biases[index])\n",
    "                        activations.append(self.sigmoid(np.dot(self.weights[index],activations[-1]) + self.biases[index]))\n",
    "                    if index==len(self.layers)-1:\n",
    "                        if self.outputActivation[0]==\"softmax\":\n",
    "                            actual_outputs.append(np.dot(self.weights[-1],activations[-1])+self.biases[-1])\n",
    "                            activations.append(self.softmax(np.dot(self.weights[-1],activations[-1])+self.biases[-1]))\n",
    "            self.activations.append(activations[-1])\n",
    "            self.actual_outputs.append(actual_outputs[-1])\n",
    "            activations= []\n",
    "            actual_outputs=[]\n",
    "\n",
    "                    \n",
    "    def loss(self,loss_type=\"cross_entropy\"):\n",
    "        if loss_type==\"mse\":\n",
    "            return 1/2*(np.square(self.outputs-np.array(self.activations[-1])))\n",
    "        elif loss_type== \"cross_entropy\":\n",
    "            return np.sum(self.outputs*np.log(np.array(self.activations[-1])) + (1-self.outputs)*np.log(1-self.activations[-1]))\n",
    "        else:\n",
    "            raise Exception('UNKNOWN ERROR')\n",
    "            \n",
    "    def backpropagate(self):\n",
    "        for eachIndex in range(len(self.inputs)):\n",
    "            num = np.array(self.activations[eachIndex]-self.outputs[eachIndex]) \n",
    "            deltas = []\n",
    "            for index in range(len(self.weights))[::-1]:\n",
    "                if index==len(self.weights)-1:\n",
    "                    delta = num*self.sigmoid(self.actual_outputs[eachIndex],derivative=True)\n",
    "                    deltas.append(delta) \n",
    "                else:\n",
    "                    delta = np.dot(self.weights[index+1].transpose(),deltas[-1])*self.sigmoid(self.actual_outputs[eachIndex],derivative=True)\n",
    "                    deltas.append(delta)\n",
    "                    if index==0:\n",
    "                        delta = np.dot(self.weights[index].transpose(),deltas[-1])*self.sigmoid(self.inputs[eachIndex],derivative=True)\n",
    "                        deltas.append(delta)\n",
    "                        print(np.array(delta).shape)\n",
    "            \n",
    "            if(eachIndex==0):\n",
    "                break           \n",
    "            self.delta_weights.append(delta*self.inputs[eachIndex])\n",
    "            self.delta_biases.append(delta)\n",
    "                    \n",
    "        return np.array(self.delta_weights),np.array(self.delta_biases)\n",
    "    \n",
    "    def GradientDescent(self):\n",
    "        self.initialize_weights()\n",
    "        for i in range(self.epochs):\n",
    "            self.feed_forward()\n",
    "            d_w,d_b = self.backpropagate()\n",
    "            self.weights = self.weights - self.learning_rate*d_w*self.weights\n",
    "            self.biases = self.biases-self.learning_rate*d_b*self.biases\n",
    "            prediction = np.dot(self.weights,self.validation)+self.biases\n",
    "            print(\"Epoch Number {} Loss {} prediction ={} \".format(i+1,self.loss(loss_type='mse'),prediction))\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "Y= []\n",
    "for i in range(10000):\n",
    "    choiceXFirst = np.random.choice([0,1])\n",
    "    choiceXSecond = np.random.choice([0,1])\n",
    "    X.append([choiceXFirst,choiceXSecond])\n",
    "    if (choiceXFirst==1 and choiceXSecond==1):\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)\n",
    "X =np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "Y = np.reshape(Y,(Y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (20,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1dc319d759e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-1c5dcfa8bf65>\u001b[0m in \u001b[0;36mGradientDescent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0md_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_b\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-1c5dcfa8bf65>\u001b[0m in \u001b[0;36mbackpropagate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mdeltas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactual_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meachIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mderivative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                     \u001b[0mdeltas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (20,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(X,Y)\n",
    "nn.add_layer(10)\n",
    "nn.add_layer(20)\n",
    "nn.initialize_weights()\n",
    "nn.feed_forward()\n",
    "nn.backpropagate()\n",
    "nn.GradientDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
